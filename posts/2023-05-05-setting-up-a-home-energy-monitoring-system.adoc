= Setting up a home energy monitoring system
eloots
v1.0, 2023-05-05
:title: Setting up a home energy monitoring system
:imagesdir: ../media/2023-05-05-setting-up-a-home-energy-monitoring-system
:lang: en
:tags: [raspberry pi, emqx, influxdb, smappee, telegraf, grafana, energy, monitoring]

[id=introduction]
== Introduction

We had been using a https://www.smappee.com/infinity[_Smappee_] system that came with our solar panel installation at home for about two years. We installed it back in July 2020 to monitor the electricity generation and consumption in our house when I noticed something odd. I used the neat _Smappee_ iOS app to check the five-minute averages to monthly averages of the energy generated by the solar panels on my roof. The system was tracking granular numbers for longer than two weeks until it abruptly changed it to two weeks.

To illustrate the issue, let’s look at a couple of sample plots. The first one is an example of 5 minute average production and consumption data for one day (August 23, 2022):

image::23-08.PNG[5 minute averages over one day on August 23rd]

The next one shows the same graphs over a period of 16 days (from August 8th till August 23rd):

image::08-16days.PNG[Production and consumption data over 16 consecutive days]

The graph shows the granularity changes from 5 minutes to an hour on August 8th.

The obvious question I asked myself was how to keep granular data longer, and I saw two options. First, I could ask the company behind the system to reinstate the longer data retention period. Second, I could investigate if I could build an energy monitoring system that would allow me to configure the data retention policy as I wished it to be. I chose option two, as it seemed to give me an opportunity to learn technologies I had never used before.

Before I found out about the data granularity issue, I had already discovered that the _Smappee_ energy management system was quite open. It provides two ways to get access to the collected data. One method is to use the _Smappee_ REST API, the other is to use https://en.wikipedia.org/wiki/MQTT[_MQTT_].

The REST API can query endpoints in the _Smappee_ Cloud, linked to an individual _Smappee_ monitoring system located, for example, in one’s house. Use of the API is free for non-commercial use and requires setting up https://oauth.net/2[OAuth2] authentication.

When using _MQTT_, the _Smappee_ monitoring system configuration has to be tweaked to point to a so-called _MQTT Broker_. Once that’s done, the _Smappee_ device will send measurement samples at a once per second interval to the _MQTT Broker_.

The first access method polls data from the _Smappee_ Cloud, while the second pushes data to a server.

With all this in mind, let’s consider the project goals I set for my Home Energy Monitoring System (_HEMS_).

[id=project-objectives]
== Project objectives

The primary aim of the _HEMS_ project was to collect _Smappee_ data at specific aggregation levels and retention periods. Also, we want dashboards that display selected aggregates over a chosen time period.

For example, a _Smappee_, when configured to send data to an _MQTT Broker_ sends data at a one-second interval. One may want to aggregate this data at minutes, days, weeks, or months intervals. Each aggregation level may have specific data retention periods. For example, we may keep the high frequency 1 minute aggregates for a few months. On the other side of the spectrum, we may keep indefinitely the monthly averages (and obviously, as long as storage capacity permits).

As I wanted to be independent of external factors (such as the _Smappee_ Cloud) as to not be exposed to the whims of external parties, I chose the _MQTT_ route for building my _HEMS_.


Next to the already cited main objective, there were other objectives I wanted to achieve:

* If possible, implement the system without any programming.
* Use _Open Source Software_ (OSS) only.
* Capture all knowledge gained in building the system as to make it easily reproducible.
* Simplify installation with automation.

We'll evaluate project objectives in the upcoming chapters.

== A brief introduction to _Smappee_

Smappees come in different versions of which I currently have two at home:

The first one, a _Smappee Solar_ came with the solar panel installation and measures the total electrical power consumption of the house and the output power of the solar panels on the roof of the house. The second one is a modular _Smappee Infinity_ that consists of:

* A _Smappee Solar_ that measures the total electrical power consumption of the house and the output power of the solar panels on the roof of the house.

* The modular _Smappee Infinity_ that comprises:

** a _Smappee Power box_ that powers all connected _Smappee_ devices and that measures line voltage(s). It supports both mono-phase and tri-phase power systems. 

** a _Smappee Genius_ which is the brain of the system. This device implements Wifi and physical Ethernet connectivity and acts as a Gateway.

** one or up-to 7 _Smappee CT Hubs_ that each can measures current in up-to 4 electrical circuits.

The _Smappee Power box_ powers the _Smappee Genius_, which is connected to the daisy chained _CT Hubs_ via https://en.wikipedia.org/wiki/RS-485[RS-485], using 4-wire twisted pair cables. These cables serve two purposes. First, they transfer power to the different _Smappee_ components. Second, they form the communication channel between the _Smappee_ components.

As mentioned in the introduction, a _Smappee_ performs measurements at a 1 Hz rate. The _Smappee_ genius measures:

- Mains frequency (Hz)
- Mains voltage(s) (V)
- Circuit currents (A)
- Real Power (W), Reactive Power (VAR), and Apparent Power (VA)

The _Smappee Solar_ is a scaled down version of the _Smappee Infinity_ system optimised for Solar panel installations.

Even though the physical installation is best performed by a professional, anyone with basic IT skills can do the configuration..

I've had the _Smappees_ in service for 3 years (_Smappee Solar_) and 9 months (_Smappee Infinity_) and both have proven to be very reliable systems.

== _HEMS_ Architecture & Implementation

=== Architecture

As mentioned in the introduction, I opted for _MQTT_ as a means to access the _Smappee_ data measurements.

The _Smappee_ documentation says the following about using _MQTT_:

image::smappee-mqtt.png[Smappee documentation about using MQTT]

_"Use of MQTT requires programming knowledge."_

Really? That's unexpected, so let's investigate.

The HEMS system needs to have the following components:

* A Time-Series database that will store aggregated measurements with an optional data retention time.

* A Display server that will offer various dashboards. The latter can be displayed on any web browser.

* An _MQTT_ Broker. It acquires raw measurements from _Smappee_ and offers them to subscribers.

* The raw _Smappee_ measurements are most likely not in a format that is suitable to write to the time-series database as-is. We may want to only keep data we’re interested in and drop other stuff. Also, it is likely that we want to rename certain data fields. Therefore, we need a component that:

** Subscribes to topics on the _MQTT Broker_.

** That transforms and aggregates the raw measurements.

** Writes it in the Time-series database.

Let’s call the last component the _IO/transformer/aggregator_.

=== Mapping of the architecture to specific components

Various alternatives exist for each component mentioned earlier, but I selected these (OSS) implementations:

* Time Series Database: https://github.com/influxdata/influxdb[InfluxDB]
* Display server: https://github.com/grafana/grafana[Grafana Server]
* _MQTT Broker_: https://github.com/emqx/emqx[EMQX]
* _IO/Transformer/aggregator_: https://github.com/influxdata/telegraf[Telegraf]

I used a Raspberry Pi with Ubuntu Server Operating System to run these components as I have great experience with this combination.

The following diagram shows the overall set-up of the _HEMS_:

image::setup-rpi-grafana-dashboard-1.png[HEMS system set-up]

Let’s walk through the elements in this diagram one by one.

==== The electricity system

The electricity system in the house is comprised of:

* A connection to the electricity grid and depicted as a lightning bolt.

* An analog electricity meter. Note that this meter measures actual power and it will turn backwards when the energy production is higher than the consumption.

> Note: in Belgium, all domestic consumers will be required to have a digital electricity meter by January 1^st^, 2025.

==== The _Smappee_ systems

- A _Smappee Solar_ that measures total energy consumption and total solar energy production.

- A _Smappee Infinity_ that measures energy consumption of different electrical devices or groups thereof. Examples of the former are the electrical furnace and dish washer. Wall sockets are grouped already and are an example of the latter.

==== The Home Energy Monitoring System

* A Raspberry Pi 4 Model B/8GB with a 250GB SSD (SATA disk connected to one of the Pi's USB-3 ports via a USB-SATA converter).

* The software components &#8212; EMQX MQTT Broker, Telegraf, InfluxDB server, and Grafana Server with data flowing from left to right.

* An _MQTT_ client &#8212; mainly used during debugging the _MQTT_/Telegraf configuration. The EMQX project has an _MQTT_ client with a Graphical User Interface named https://github.com/emqx/MQTTX[MQTTX], but due to it being pretty slow, I switched to https://github.com/eclipse/mosquitto[Mosquitto] CLI.

* I added the Raspberry Pi OS Metrics Telegraf configuration and Grafana Dashboard to monitor the Raspberry Pi.

With this out of the way, we will look at configuration and system provisioning in the next chapters.

== System provisioning

It is a well-established fact that the Internet provides a wealth of information about setting up IT infrastructure and software. Obtaining accurate information can be a challenge though.

For example, take the _absolutely great_ https://grafana.com/grafana/dashboards/10578-raspberry-pi-monitoring[Raspberry Pi Grafana dashboard] developed by Jorge de la Cruz. I installed and configured this component before tackling the energy monitoring part. When I added the latter, the Raspberry Pi monitoring dashboard stopped working. An analysis showed that the Telegraf configuration for the Raspberry Pi system monitoring was too generic.

Another challenge I faced was determining what software component versions are supported by a particular operating system. As I am using Ubuntu Server OS, two versions, 20.04 and 22.04 were suitable candidates, with a preference for version 22.04. Unfortunately, at the time I installed the system, they only supported EMQX on 20.04, which made 22.04 a no-go (at the time of writing https://www.emqx.io/docs/en/v5.0/deploy/install.html#supported-operating-systems[EMQX on Ubuntu 22.04] _is_ supported).

A way to avoid having to go through a debugging cycle when provisioning a system is to use tools to automate the process as much as possible. Various alternatives exist, but I went for https://cloudinit.readthedocs.io/en/latest/index.html[_cloud-init_].

As Ubuntu Server bundles _cloud-init_, we can use it to our advantage. We can provision a new system in a reproducible way, and we can do so in the fastest way possible. Compared to a manual installation and configuration, at least an order of magnitude faster. We can provision the _HEMS_ system in the time span of about 15 minutes. SD card flash time is consuming a sizable fraction of the total time.

In fact, after having gone through several iterations, I found out that we can optimise further it. Even though Ubuntu 20.04 doesn’t support booting of an external SSD, it still does so provided that there’s a bootable SD card installed on the Pi. The net effect is that the SD card needs to be flashed just once and only the SSD needs to be re- flashed. Given that it takes about 18 seconds to do this, we shortened the provisioning process by several minutes.

Ubuntu 22.04 supports direct booting of an external SSD obviating the need to have an SD card installed on the Pi.

I plan to upgrade my current production system to the latest and greatest somewhere down the line. Have a look at <<future-work>> for a list of ideas.

== Configuring _MQTT_ on the _Smappees_

We can configure a _Smappee_ to send its measurements to an _MQTT Broker_ in the advanced configuration menu of the _Smappee_. For this configuration, we need the IP address of the broker and the port number it is listening on (default = 1883).

The following screenshot shows the advanced configuration screen of a _Smappee_.

image::smappee_mqtt_config_1.png[Smappee advanced configuration screen]

Note that the configuration set the broker’s IP address to 192.168.68.201, the port number to 1883, and the transport layer communication protocol to TCP.

With that configuration change, each _Smappee_ will now start sending _MQTT_ data to the broker. Note that we will lose data if the configuration is incorrect (e.g. wrong IP address or port number). Also, if the broker is down or unreachable, we will lose data.

_MQTT_ sends data on so-called _MQTT topics_. Different options exist for encoding the actual data, but _Smappee_ opts for JSON encoding.

The structure of the data is different between the _Smappee Solar_ and the _Smappee Genius_. Let's start with the Solar and then look at the other.

```bash
$ mosquitto_sub -h 192.168.68.201 -p 1883 -t servicelocation/f960f45d-c43b-4937-a8d0-ce1869206011/realtime| jq
{
  "totalPower": 255,
  "totalReactivePower": 251,
  "totalExportEnergy": 0,
  "totalImportEnergy": 807413694,
  "monitorStatus": 0,
  "utcTimeStamp": 1683799083538,
  "channelPowers": [
    {
      "ctInput": 1,
      "power": 1175,
      "exportEnergy": 6848910,
      "importEnergy": 884498523,
      "phaseId": 1,
      "current": 49
    },
    {
      "ctInput": 2,
      "power": 255,
      "exportEnergy": 0,
      "importEnergy": 807413694,
      "phaseId": 2,
      "current": 15
    }
  ],
  "voltages": [
    {
      "voltage": 241,
      "phaseId": 0
    }
  ]
}
```

On this device, the data we're interested in are the line voltage (`voltages/voltage`), the two power readings (`channelPowers/power` for `channelPowers.ctInput = 1` and `channelPowers.ctInput = 2`) ,and the timestamp of the measurement. We will explain later how this data is extracted and transformed before writing it to InfluxDB.

For the _Smappee Genius_, the (abbreviated) data looks as follows:

```bash
$ mosquitto_sub -h 192.168.68.201 -p 1883 -t servicelocation/5aaf6e89-89cb-4e33-bf34-05abc62f5563/realtime| jq
{
  "totalPower": 0,
  "totalReactivePower": 0,
  "totalExportEnergy": 5900400,
  "totalImportEnergy": 3332883600,
  "monitorStatus": 0,
  "utcTimeStamp": 1683799714000,
  "measuredFrequency": 49983008,
  "channelPowers": [
    {
      "publishIndex": 0,
      "formula": "$5500053415/0$",
      "power": 84,
      "exportEnergy": 2188800,
      "importEnergy": 280227600,
      "phaseId": 0,
      "current": 4,
      "apparentPower": 90,
      "cosPhi": 93
    },
    {
      "publishIndex": 1,
      "formula": "$5500053415/1$",
      "power": 7,
      "exportEnergy": 900000,
      "importEnergy": 277783200,
      "phaseId": 0,
      "current": 1,
      "apparentPower": 21,
      "cosPhi": 33
    },    
    <elided>
  ],
  "voltages": [
    {
      "voltage": 242,
      "phaseId": 0
    },
    <elided>
  ]
}
```

The _Smappee Genius_ collects more information than its smaller sibling. Observe the `measuredFrequency` measurement (expressed in µHz) which allows us to track the mains AC frequency, `channelPowers.cosPhi`, measures the so-called <<cos-phi>> or power factor on a per channel basis. Interesting to note is the `channelPowers.formula` value which is the _CT Hub_ Id. This Id is a 10-digit number that uniquely identifies each _CT Hub_.

The following diagram shows the physical configuration & measurement points on the _Smappee Infinity" system.

image::smappee-connection-diagram.png[Smappee connection diagram]

We recognise the four _CT Hubs_ with their respective Id and what each _CT Hub_ channel measures. The labels _Ground Floor_ and _2nd Floor_ at the top of the diagram refer to the location of the fuse panel in which the _Smappee_ components are located.

Now that we know the message format of the raw data published via _MQTT_, we will look at how we can get the messages into the Time series database.

=== Configuring Telegraf

Telegraf offers a series of plugins that fall into different categories. Telegraf plugins that are relevant to our use case are:

* Input: https://docs.influxdata.com/telegraf/v1.26/plugins/#input-mqtt_consumer[MQTT Consumer] and the https://docs.influxdata.com/telegraf/v1.21/data_formats/input/json_v2[JSON v2 parser]. The JSON v2 parser is a generic component that can apply to any input plugin.

* Aggregator: https://docs.influxdata.com/telegraf/v1.26/plugins/#aggregator-basicstats[Basic Stats]

* Processor: https://docs.influxdata.com/telegraf/v1.26/plugins/#processor-regex[Regex] 

* Output: https://docs.influxdata.com/telegraf/v1.23/plugins/#output-influxdb[InfluxDB v1.x]

==== Reading and transforming the MQTT data sources

Our two _Smappees_ send data to the _EMQX_ _MQTT_ broker located at `tcp://192.168.68.201:1883`. Let’s look at the relevant part of the (partial) Telegraf configuration for the _Smappee Genius_.

```toml
[[inputs.mqtt_consumer]]
  alias = "smappee-2"
  name_override = "smappee-data-2"
  servers = ["tcp://192.168.68.201:1883"]
  topics = [
    "servicelocation/5aaf6e89-89cb-4e33-bf34-05abc62f5563/realtime"
  ]
  # The "host" tag is irrelevant in this use case. Drop it
  tagexclude = ["host"]
  data_format = "json_v2"
  [[inputs.mqtt_consumer.json_v2]]
    [[inputs.mqtt_consumer.json_v2.field]]
      path = "channelPowers.#(formula==$5500048161/0$).power"
      rename = "zolder-verlichting"
      type = "float"
    [[inputs.mqtt_consumer.json_v2.field]]
      path = "channelPowers.#(formula==$5500048161/1$).power"
      rename = "zolder-stopkontakten-network-switch"
      type = "float"
    [[inputs.mqtt_consumer.json_v2.field]]
      path = "channelPowers.#(formula==$5500048161/2$).power"
      rename = "tuinhuis-fietsgarage"
      type = "float"
      
  <elided>
```

We are configuring the `mqtt_consumer` input plugin and point it to connect to the _EMQX_ broker. The `topics` settings is used to instruct the plugin to subscribe to the _MQTT_ topic of interest. Next, the `name_override` setting is used to name the stream of data elements produced by the input plugin. This name is used to select the desired route that the data will follow as other plugins process it. Finally, the data is in JSON format (`json_v2`) and we exclude the host field.

We're ready to configure the JSON parser, which is done in the `inputs.mqtt_consumer.json_v2` configuration section. For each field in the data that we want to retain for further processing, there's a section that selects the field, renames it, and specifies its format.

You may wonder how one knows the syntax of the `path` selector. A very handy tool for this is the https://gjson.dev[GJSON playground] which allows one to try out queries on JSON data. It comes with examples for the most important use cases.

Here are two examples of queries on the _Smappee Genius_ data. These respectively extract the `measuredFrequency` value and the `power` value for channel 0 on the _CT Hub_ with Id `5500053415`.

image::GJSON-measured-frequency.png[GJSON - Extracting power for channel 0 on CT Hub 5500053415]  

image::GJSON-measured-power.png[GJSON - Extracting measuredFrequency]

==== Transforming the _MQTT_ topic

If we would limit the Telegraf configuration to what we have up to now, the data would be tagged with the rather lengthy topic (`servicelocation/5aaf6e89-89cb-4e33-bf34-05abc62f5563/realtime`). It makes sense to drop the `servicelocation` and the `realtime` parts. We can do this using the _regex_ processor by adding the following configuration.

```toml
[[processors.regex]]
  namepass = ["smappee-data-2"]
  [[processors.regex.tags]]
    key = "topic"
    pattern = ".*/(.*)/.*"
    replacement = "smappee/${1}"
```

We can be observe:

* By specifying the `namepass` setting, the processor will only apply to the data we want to transform. If we would leave it out, the transformation would be applied on _all_ data.

* We select the `topic` key and apply a pattern match on its value via a regular expression which captures the value of the second field.

* The original topic value, `servicelocation/5aaf6e89-89cb-4e33-bf34-05abc62f5563/realtime`, is replaced by the new value `smappee/5aaf6e89-89cb-4e33-bf34-05abc62f5563`.

==== Aggregating the data

Writing the measurements at the _Smappee_ 1Hz sample rate is overkill, so we want to aggregate measurements at a longer interval. I kept average values over 1-minute intervals. We can implement this using the _basicstats_ Telegraf aggregator plugin.

Here's the configuration for this:

```toml
[[aggregators.basicstats]]
  namepass = ["smappee-data-2"]
  ## The period on which to flush & clear the aggregator.
  period = "60s"

  ## If true, the original metric will be dropped by the
  ## aggregator and will not get sent to the output plugins.
  drop_original = true

  ## Configures which basic stats to push as fields
  stats = ["mean"]
```

The usage of the `namepass` setting should be familiar by now. Other than that, we set the aggregation interval to 60 seconds (setting `period`) and we drop the original (1 second) measurements as we only want the plugin to calculate the average value via the `stats` setting.

We could also choose to let Telegraf handle further aggregation to longer intervals, but that's a task that is better left to InfluxDB as the latter will also help use to specify data retention times.

All that's left to do is to write the data to the Time series database.

==== Writing the processed data to InfluxDB

An InfluxDB server is running on the same host (`http://192.168.68.201:8086`). The only thing missing is the Telegraf InfluxDB output plugin configuration:

```toml
[[outputs.influxdb]]
  namepass = ["smappee-data-2"]
  alias = "smappee-out-2"
  urls = ["http://192.168.68.201:8086"]
  database = "smappee_monitoring_2"
  username = "this is not my username"
  password = "this is not my password"
```

This configuration is for InfluxDB version 1. We should not pass the database username & password in the config. I will revisit this as part of a future migration to InfluxDB version 2, which has a completely revised security implementation.

==== Lessons learned from setting up Telegraf and InfluxDB

===== Telegraf - message routing through plugins

The Telegraf plugin system is powerful, but it took me quite some time to wrap my head around its configuration. Even though there are video tutorials and online courses on various Telegraf related topics, it took me a lot of time to grasp how data is routed through the system by applying the `name_override`, `namepass`, and `namedrop` parameters. When it finally dawned on me how it works, it looked trivial (and it actually _is_).

===== Telegraf - plugin application order

The order of application of Telegraf plugins is:

* _Input_ plugins

* _Processer_ plugins

* _Aggregator_ plugins

* _Output_ plugins

For _Processor_ plugins, we can tweak the order of execution by setting the order parameter on all processors involved.

The https://github.com/influxdata/telegraf/blob/master/docs/CONFIGURATION.md[Telegraf configuration document] is worth reading and provides a lot of very useful information that you may want to read before embarking for the first time on a Telegraf project.

==== Telegraf - conclusion

The _HEMS_ has a relatively simple Telegraf configuration. The configuration can be put in a single file (`/etc/telegraf/telegraf.conf`), or across multiple files located in the `/etc/telegraf/telegraf.d` folder. An advantage of using multiple configuration files is that the configs for different _Smappee_ systems can be separated. In fact, when I recently added some _Zigbee 3.0_ devices that connect to a _Zigbee2MQTT_ bridge configured in a Home Automation system, its Telegraf configuration was stored in a dedicated file.One thing to be aware of is that using multiple configuration files doesn’t introduce any separation between the individual configs, so treat it as if everything was stored in a single file.

A cool feature of Telegraf is that the `telegraf` CLI can generate a configuration file for a list of Telegraf plugins with all possible setting applicable to the chosen plugins.

I think that in a complex system, it's challenging to maintain the Telegraf configuration(s). InfluxDB version 2 probably has features that simplify managing this, but that’s something I haven’t explored yet.

==== InfluxDB

Installation and configuration of InfluxDB version 1 is simple. I automated the installation using _cloud-init_, including the creation of the user databases & user account.

I spent little time securing the set-up as I think InfluxDB version 2 has a lot more to offer.

Actually, when I started this project, I wasn’t aware of the fact that there is a version 2 of InfluxDB. I found out by the time the project was already long underway. I did a small trial by uninstalling version 1 followed by an installation of version 2. What I found impressive is that when I first started the new version 2 instance; it told me it had detected version 1 databases and if I wanted them converted to version 2. I accepted the offer and it worked flawlessly. What I liked even more is that when I reverted the installation to version 1, my original data was still there and ready to continue where I left off. Pretty impressive, if you ask me.

=== Provisioning the _HEMS_ system with _cloud-init_

_cloud-init_ is a method for cross-platform instance initialisation. We can utilise _cloud-init_ for cross-platform instance initialisation, even on bare-metal installations like on a Raspberry Pi. It performs user creation, execute custom scripts, install packages, create files, partition disk, create file systems, etc.

It used to have rather poor documentation, but this is a thing of the past. When you want to start with _cloud-init_, have at the https://cloudinit.readthedocs.io/en/latest/reference/examples.html[Cloud Config Examples] which should get you started quickly. These examples are part of the https://cloudinit.readthedocs.io/en/latest/reference/index.html[Reference Documentation] on the https://cloudinit.readthedocs.io/en/latest/[_cloud-init_ website].

==== Using _cloud-init_

I started using _cloud-init_ many years ago on another Raspberry Pi project. Back then, I used the _Hypriot_ operating system (a derivative of https://www.raspberrypi.com/software[Raspbian]) which has integrated support for _cloud-init_ and _Docker_. The Hypriot OSS project has gone dormant for a few years, but one of the contributors pointed out that Ubuntu Server has the same goodies incorporated. I switched to Ubuntu and never looked back.

A _cloud-init_ deployment is driven by a cloud-config file in YAML format. You can find the configuration for this project https://github.com/eloots/home-energy-monitoring-system-setup/blob/main/cloud-init/smappee-2.yml[here]. It's part of the _HEMS_ GitHub repository that also contains the Telegraf configuration https://github.com/eloots/home-energy-monitoring-system-setup/blob/main/telegrafConfiguration/etc/telegraf/telegraf.d/smappee-2.conf[smappee-2.conf] for the _Smappee Genius_ and https://github.com/eloots/home-energy-monitoring-system-setup/blob/main/telegrafConfiguration/etc/telegraf/telegraf.d/smappee.conf[smappee.conf] for the _Smappee Solar_.

Noteworthy mentioning is that _cloud-init_ supports instance data with [jinja] template rendering. Instead of directly applying configuration settings in the _cloud-config_ file, metadata comprising key/value pairs can be passed to _cloud-init_ in a file and these can be de-referenced in the _cloud-config_ file.

For the Ubuntu _cloud-init_ installation, I adapted the _Hypriot_ `flash` command supports passing in the metadata file during flashing. You can find this version https://github.com/eloots/flash/releases[here].

Here's an example invocation of the command to flash an SSD (or SD) with Ubuntu 22.04

```bash
$ flash -n home-iot -j -m cloud-init/meta-data -u cloud-init/smappee-2.yml \
  https://cdimage.ubuntu.com/releases/22.04/release/ubuntu-22.04.2-preinstalled-server-arm64+raspi.img.xz
```

=== Conclusion

The <<project-objectives>> set at the start of the project were all achieved.

No programming was required to build the _HEMS_. All software components are OSS, and we can provision a new _HEMS_ system in a matter of minutes.

The only thing that needs to be done is to point the _MQTT_ data providers to it. Finally, and that’s about the only manual step, we configure Grafana data sources and import Grafana dashboards.

<<<
[id=cos-phi]
=== Electrical Power Factor (also known as cos(&#966;))

The Power Factor is a measure of an electrical system's efficiency. In that respect, the power consumed can be decomposed in three parts:

* P~a~: Apparent power, which is the product of the measured voltage and current.

* P~real~: Productive or Real Power is the part that actually produces work in the broad sense of the word, it's not the internal efficiency of the device itself. For example, an incandescent lightbulb consuming 100W converts 98W to heat and only 2W to light. So, in this case, the Productive Power is 100W.

* P~reactive~: Reactive power (VAR - Volt-Ampère-Reactive) which is the part that doesn't perform any work, but that still results in energy flowing between the electricity producer and consumer.

The relation between these components is the following:

* P^2^~a~ = P^2^~real~ + P^2^~reactive~

* P~real~ = P~a~ . cos(&#966;)

* P~reactive~ = P~a~ . sin(&#966;)

In electrical systems, cos(&#966;) is a value between 0 and 1. When the reactive power is 0, cos(&#966;) is equal to 1 and P~a~ and P~real~ have equal values.

On the other extreme, P~reactive~ is equal to P~a~, and P~real~ and cos(&#966;) are both 0.

Both the real- and the reactive power components transfer energy between energy producer and consumer. The real power component corresponds to a unidirectional transfer of energy from producer to consumer. The reactive power component corresponds to energy being bounced back and forth between producer and consumer.

If we look at the bigger picture, both are transferred through the grid via high voltage transmission lines, transformers, and local power distribution systems. During this transfer, losses occur amounting to 6% to 8% of the total energy produced.

Companies that produce and sell electricity want the reactive power to be 0 or tiny compared to the apparent power. This is because, in principle, the transmission losses generated by the reactive power aren’t billable to consumers. With the explosion of devices with internal switching power supplies such as mobile phones and laptop computers, this poses a real challenge as these supplies exhibit a poor cos(&#966;). Regulations are being put in place to force manufacturers to address this issue.

When measuring the cos(&#966;) of various equipment in the house, I noticed that the charger in the electrical car has a cos(&#966;) that is pretty much equal to 1, which means that it exhibits close to perfect behaviour. This is especially important as the power consumed during the charging is in the order of multiple kilo Watts. On the other hand, the charger of our electrical bicycle charger's cos(&#966;) is only 0.69. So, when charging, the different powers are P~real~ = 180W, P~a~ = 260VA, and P~reactive~ = 187W. Even though it's "only 187W", when thousand or millions of such devices are online, the impact _is_ significant.  

<<<
[id=future-work]
=== Future work

* Upgrade of the production system without any loss of data
** Upgrade Ubuntu 20.04 to Ubuntu 22.04
** Upgrade InfluxDB v1 to InfluxDB v2

* Add pricing data to the system
** Add dashboards that display the price of electricity imported from (and exported to) the grid over a specified period and for specific consumers

* Actively control electricity consumption to:
** Reduce peak consumption
** Drive down the electricity bill by shifting consumption to moments where the prices are lower. Candidate consumers are electrical water boilers and electric cars



